import gradio as gr
import json
import os
from typing import List
from openai import OpenAI
import requests
from PIL import Image
from io import BytesIO
import re

# APIé…ç½®
API_KEY = ""
BASE_URL = "https://api-inference.modelscope.cn/v1/"
MODEL_NAME = "deepseek-ai/DeepSeek-V3.2"

def init_openai_client():
    return OpenAI(base_url=BASE_URL, api_key=API_KEY)

def clean_response(text):
    """æ¸…ç†å“åº”æ–‡æœ¬ï¼Œç§»é™¤æ€è€ƒè¿‡ç¨‹æ ‡è®°"""
    # ç§»é™¤ <thinking>...</thinking> æ ‡ç­¾åŠå†…å®¹
    text = re.sub(r'<thinking>.*?</thinking>', '', text, flags=re.DOTALL)
    # ç§»é™¤å…¶ä»–å¯èƒ½çš„æ€è€ƒè¿‡ç¨‹æ ‡è®°
    text = re.sub(r'\[?æ€è€ƒè¿‡ç¨‹\]?:.*?(?=\n\n|\nã€|\n=)', '', text, flags=re.DOTALL)
    # æ¸…ç†å¤šä½™çš„ç©ºè¡Œ
    text = re.sub(r'\n\s*\n', '\n\n', text)
    return text.strip()

def generate_destination_recommendation(season, health_condition, budget, interests):
    client = init_openai_client()
    system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è€å¹´æ—…è¡Œè§„åˆ’å¸ˆã€‚æ ¹æ®ç”¨æˆ·çš„å­£èŠ‚ã€å¥åº·çŠ¶å†µã€é¢„ç®—å’Œå…´è¶£ï¼Œæ¨è3-5ä¸ªå›½å†…å¤–çƒ­é—¨é€‚è€ç›®çš„åœ°ã€‚
æ¯ä¸ªæ¨èåº”åŒ…æ‹¬ï¼šç›®çš„åœ°åç§°ã€æ¨èç†ç”±ã€æœ€ä½³æ—…è¡Œæ—¶é•¿ã€æ³¨æ„äº‹é¡¹ã€‚è¯·ç”¨é€šä¿—æ˜“æ‡‚çš„è¯­è¨€å›å¤ã€‚"""
    
    user_prompt = f"å­£èŠ‚ï¼š{season}ï¼Œå¥åº·çŠ¶å†µï¼š{health_condition}ï¼Œé¢„ç®—ï¼š{budget}ï¼Œå…´è¶£åå¥½ï¼š{interests}"
    
    result = ""
    try:
        response = client.chat.completions.create(
            model=MODEL_NAME,
            messages=[
                {'role': 'system', 'content': system_prompt},
                {'role': 'user', 'content': user_prompt}
            ],
            stream=True
        )
        for chunk in response:
            answer_chunk = chunk.choices[0].delta.content
            if answer_chunk:
                result += answer_chunk
        result = clean_response(result)
    except Exception as e:
        result = f"[é”™è¯¯] ç”Ÿæˆæ¨èæ—¶å‡ºé”™ï¼š{str(e)}"
    
    return result

def generate_itinerary_plan(destination, duration, mobility, health_focus):
    client = init_openai_client()
    system_prompt = """ä½ æ˜¯ä¸€ä¸ªç»éªŒä¸°å¯Œçš„è€å¹´æ—…è¡Œè¡Œç¨‹è§„åˆ’å¸ˆã€‚è¯·ä¸ºè€å¹´äººåˆ¶å®šèˆ’ç¼“ã€è´´å¿ƒçš„æ—¥è¡Œç¨‹å®‰æ’ã€‚"""
    
    user_prompt = f"ç›®çš„åœ°ï¼š{destination}ï¼Œæ—…è¡Œæ—¶é•¿ï¼š{duration}ï¼Œè¡ŒåŠ¨èƒ½åŠ›ï¼š{mobility}ï¼Œå¥åº·å…³æ³¨ç‚¹ï¼š{health_focus}"
    
    result = ""
    try:
        response = client.chat.completions.create(
            model=MODEL_NAME,
            messages=[
                {'role': 'system', 'content': system_prompt},
                {'role': 'user', 'content': user_prompt}
            ],
            stream=True
        )
        for chunk in response:
            answer_chunk = chunk.choices[0].delta.content
            if answer_chunk:
                result += answer_chunk
        result = clean_response(result)
    except Exception as e:
        result = f"[é”™è¯¯] ç”Ÿæˆè¡Œç¨‹æ—¶å‡ºé”™ï¼š{str(e)}"
    
    return result

def generate_checklist(destination, duration, special_needs):
    client = init_openai_client()
    system_prompt = """ä½ æ˜¯ä¸€ä¸ªç»†å¿ƒçš„è€å¹´æ—…è¡ŒåŠ©æ‰‹ã€‚è¯·ä¸ºè€å¹´äººåˆ¶å®šè¯¦ç»†çš„è¡Œå‰å‡†å¤‡æ¸…å•ï¼ŒæŒ‰ç±»åˆ«åˆ†ç»„ï¼Œæ ‡æ³¨å¿…éœ€å“å’Œå¯é€‰ç‰©å“ã€‚"""
    
    user_prompt = f"ç›®çš„åœ°ï¼š{destination}ï¼Œæ—…è¡Œæ—¶é•¿ï¼š{duration}ï¼Œç‰¹æ®Šéœ€æ±‚ï¼š{special_needs}"
    
    result = ""
    try:
        response = client.chat.completions.create(
            model=MODEL_NAME,
            messages=[
                {'role': 'system', 'content': system_prompt},
                {'role': 'user', 'content': user_prompt}
            ],
            stream=True
        )
        for chunk in response:
            answer_chunk = chunk.choices[0].delta.content
            if answer_chunk:
                result += answer_chunk
        result = clean_response(result)
    except Exception as e:
        result = f"[é”™è¯¯] ç”Ÿæˆæ¸…å•æ—¶å‡ºé”™ï¼š{str(e)}"
    
    return result

def generate_travel_story(photos, custom_input):
    client = init_openai_client()
    system_prompt = """ä½ æ˜¯ä¸€ä¸ªæ¸©æš–çš„è€å¹´æ—…è¡Œæ•…äº‹è®²è¿°è€…ã€‚è¯·æ ¹æ®ç…§ç‰‡å’Œæ–‡å­—ç”Ÿæˆæ¸©é¦¨ã€æ„Ÿäººçš„æ—…è¡Œæ¸¸è®°ï¼Œè¯­è¨€äº²åˆ‡æ¸©é¦¨ï¼Œå……æ»¡æ­£èƒ½é‡ã€‚"""
    
    user_prompt = f"ç”¨æˆ·è¡¥å……ä¿¡æ¯ï¼š{custom_input}"
    
    result = ""
    try:
        response = client.chat.completions.create(
            model=MODEL_NAME,
            messages=[
                {'role': 'system', 'content': system_prompt},
                {'role': 'user', 'content': user_prompt}
            ],
            stream=True
        )
        for chunk in response:
            answer_chunk = chunk.choices[0].delta.content
            if answer_chunk:
                result += answer_chunk
        result = clean_response(result)
    except Exception as e:
        result = f"[é”™è¯¯] ç”Ÿæˆæ¸¸è®°æ—¶å‡ºé”™ï¼š{str(e)}"
    
    return result

def create_app():
    with gr.Blocks(title="ğŸ§³ é“¶å‘æ—æ™ºèƒ½æ—…è¡ŒåŠ©æ‰‹", theme=gr.themes.Soft(primary_hue="purple", secondary_hue="cyan")) as app:
        gr.HTML('<h1 style="text-align:center;font-size:48px;">ğŸ§³ é“¶å‘æ—æ™ºèƒ½æ—…è¡ŒåŠ©æ‰‹</h1>')
        
        with gr.Tabs():
            with gr.Tab("ğŸŒ æ™ºèƒ½æ¨èä¸è§„åˆ’"):
                with gr.Row():
                    with gr.Column():
                        season = gr.Dropdown(["æ˜¥å­£", "å¤å­£", "ç§‹å­£", "å†¬å­£"], label="ğŸŒ¸ å­£èŠ‚", value="ç§‹å­£")
                        health = gr.Dropdown(["èº«ä½“å¥åº·", "æœ‰æ…¢æ€§ç—…ä½†æ§åˆ¶è‰¯å¥½"], label="ğŸ¥ å¥åº·çŠ¶å†µ", value="èº«ä½“å¥åº·")
                        budget = gr.Dropdown(["ç»æµå®æƒ ", "èˆ’é€‚å‹", "è±ªåå‹"], label="ğŸ’° é¢„ç®—", value="èˆ’é€‚å‹")
                        interests = gr.Textbox(label="ğŸ¨ å…´è¶£åå¥½", value="é¿å¯’ã€åº·å…»")
                        btn1 = gr.Button("ğŸ” æ¨èç›®çš„åœ°", variant="primary")
                        output1 = gr.Textbox(label="âœ¨ æ¨èç»“æœ", lines=20)
                        btn1.click(fn=generate_destination_recommendation, inputs=[season, health, budget, interests], outputs=[output1])
                    
                    with gr.Column():
                        dest = gr.Textbox(label="ğŸ“ ç›®çš„åœ°")
                        dur = gr.Dropdown(["3-5å¤©", "ä¸€å‘¨å·¦å³", "10-15å¤©"], label="â° æ—…è¡Œæ—¶é•¿", value="ä¸€å‘¨å·¦å³")
                        mobility = gr.Dropdown(["è¡Œèµ°è‡ªå¦‚", "éœ€è¦å°‘é‡ä¼‘æ¯"], label="ğŸš¶ è¡ŒåŠ¨èƒ½åŠ›", value="è¡Œèµ°è‡ªå¦‚")
                        health_focus = gr.Textbox(label="â¤ï¸ å¥åº·å…³æ³¨ç‚¹")
                        btn2 = gr.Button("ğŸ“‹ åˆ¶å®šè¡Œç¨‹", variant="primary")
                        output2 = gr.Textbox(label="âœ¨ è¡Œç¨‹å®‰æ’", lines=20)
                        btn2.click(fn=generate_itinerary_plan, inputs=[dest, dur, mobility, health_focus], outputs=[output2])
            
            with gr.Tab("ğŸ“ æ¸…å•ä¸å¯¼æ¸¸æœåŠ¡"):
                with gr.Row():
                    with gr.Column():
                        checklist_dest = gr.Textbox(label="ğŸ“ ç›®çš„åœ°")
                        checklist_dur = gr.Dropdown(["3-5å¤©", "ä¸€å‘¨å·¦å³"], label="â° æ—…è¡Œæ—¶é•¿", value="ä¸€å‘¨å·¦å³")
                        checklist_needs = gr.Textbox(label="âš•ï¸ ç‰¹æ®Šéœ€æ±‚")
                        btn3 = gr.Button("ğŸ“‹ ç”Ÿæˆæ¸…å•", variant="primary")
                        output3 = gr.Textbox(label="âœ¨ æ¸…å•å†…å®¹", lines=20)
                        btn3.click(fn=generate_checklist, inputs=[checklist_dest, checklist_dur, checklist_needs], outputs=[output3])
            
            with gr.Tab("ğŸ¬ æ—…è¡Œæ¸¸è®°ç”Ÿæˆ"):
                with gr.Row():
                    with gr.Column():
                        photos = gr.File(file_count="multiple", file_types=["image"], label="ğŸ“· ä¸Šä¼ æ—…è¡Œç…§ç‰‡")
                        story_input = gr.Textbox(label="âœï¸ è¡¥å……ä¿¡æ¯", lines=5)
                        btn4 = gr.Button("âœ¨ ç”Ÿæˆæ¸¸è®°", variant="primary")
                        output4 = gr.Textbox(label="âœ¨ æ¸¸è®°å†…å®¹", lines=20)
                        btn4.click(fn=generate_travel_story, inputs=[photos, story_input], outputs=[output4])
    
    return app

if __name__ == "__main__":
    app = create_app()
    app.launch(server_name="0.0.0.0", server_port=7860, inbrowser=True)
